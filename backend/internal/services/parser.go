package services

import (
	"fmt"
	"io"
	"net/http"
	"net/url"
	"strings"
	"time"
)

type ParserService struct {
	httpClient *http.Client
}

func NewParserService() *ParserService {
	return &ParserService{
		httpClient: &http.Client{
			Timeout: 60 * time.Second, // å¢åŠ åˆ° 60 ç§’ï¼Œé€‚åº”åŠ è½½è¾ƒæ…¢çš„é¡µé¢
		},
	}
}

// ExtractedContent æå–çš„å†…å®¹
type ExtractedContent struct {
	Title     string `json:"title"`
	URL       string `json:"url"`
	Content   string `json:"content"`
	Timestamp string `json:"timestamp"`
}

// ProxyResponse All Origins API å“åº”
type ProxyResponse struct {
	Contents string `json:"contents"`
	Type     string `json:"type"`
}

func (s *ParserService) ParseURL(targetURL string) (*ExtractedContent, error) {
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Println("ğŸ” å¼€å§‹è§£æ URL")
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Printf("ğŸ“¡ ç›®æ ‡ URL: %s\n", targetURL)
	startTime := time.Now()

	// éªŒè¯ URL
	if _, err := url.Parse(targetURL); err != nil {
		return nil, fmt.Errorf("URL æ ¼å¼é”™è¯¯: %w", err)
	}

	// ç›´æ¥è¯·æ±‚ç›®æ ‡ URL è·å–å†…å®¹
	fmt.Println("\nğŸ“¡ æ­¥éª¤ 1: ç›´æ¥è·å–ç½‘é¡µå†…å®¹")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

	// åˆ›å»ºè‡ªå®šä¹‰è¯·æ±‚ï¼Œæ·»åŠ æµè§ˆå™¨å¤´éƒ¨
	req, err := http.NewRequest("GET", targetURL, nil)
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %w", err)
	}

	// è®¾ç½®æµè§ˆå™¨ User-Agent å’Œå…¶ä»–å¤´éƒ¨ï¼Œé¿å…è¢«è¯†åˆ«ä¸ºçˆ¬è™«
	req.Header.Set("User-Agent", "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
	req.Header.Set("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8")
	req.Header.Set("Accept-Language", "zh-CN,zh;q=0.9,en;q=0.8")
	req.Header.Set("Cache-Control", "no-cache")
	req.Header.Set("Pragma", "no-cache")

	fetchStartTime := time.Now()
	resp, err := s.httpClient.Do(req)
	if err != nil {
		return nil, fmt.Errorf("è¯·æ±‚å¤±è´¥: %w", err)
	}
	defer resp.Body.Close()

	fetchTime := time.Since(fetchStartTime)
	fmt.Printf("âœ… å“åº”çŠ¶æ€: %d %s\n", resp.StatusCode, resp.Status)
	fmt.Printf("â±ï¸  è¯·æ±‚è€—æ—¶: %dms\n", fetchTime.Milliseconds())

	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("HTTP é”™è¯¯: %d %s", resp.StatusCode, resp.Status)
	}

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–å“åº”å¤±è´¥: %w", err)
	}

	htmlContent := string(body)
	fmt.Printf("ğŸ“¦ HTML å†…å®¹é•¿åº¦: %d å­—ç¬¦\n", len(htmlContent))

	if len(htmlContent) == 0 {
		return nil, fmt.Errorf("å“åº”ä¸­æ²¡æœ‰å†…å®¹")
	}

	fmt.Println("ğŸ“ æ­¥éª¤ 2: è§£æ HTML å†…å®¹")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

	// ç»Ÿè®¡ HTML å…ƒç´ 
	contentLower := strings.ToLower(htmlContent)
	paragraphsCount := strings.Count(contentLower, "<p")
	headingsCount := strings.Count(contentLower, "<h") + strings.Count(contentLower, "<H")
	listsCount := strings.Count(contentLower, "<li") + strings.Count(contentLower, "<LI")
	scriptsCount := strings.Count(contentLower, "<script")
	stylesCount := strings.Count(contentLower, "<style")

	fmt.Println("ğŸ“Š HTML å…ƒç´ ç»Ÿè®¡:")
	fmt.Printf("   æ®µè½ (p): %d\n", paragraphsCount)
	fmt.Printf("   æ ‡é¢˜ (h1-h6): %d\n", headingsCount)
	fmt.Printf("   åˆ—è¡¨é¡¹ (li): %d\n", listsCount)
	fmt.Printf("   è„šæœ¬ (script): %d\n", scriptsCount)
	fmt.Printf("   æ ·å¼ (style): %d\n", stylesCount)

	// ç®€å•çš„ HTML è§£æï¼ˆæå–æ ‡é¢˜ã€æè¿°ã€æ®µè½ï¼‰
	title := extractTitle(htmlContent)
	fmt.Printf("\nğŸ“Œ æå–çš„æ ‡é¢˜: %s\n", title)

	metaDesc := extractMetaDescription(htmlContent)
	fmt.Printf("ğŸ“Œ æå–çš„æè¿°: %s...\n", truncateString(metaDesc, 100))
	fmt.Printf("   æè¿°é•¿åº¦: %d å­—ç¬¦\n", len(metaDesc))

	// æ¸…ç† HTML æ ‡ç­¾
	fmt.Println("\nğŸ§¹ æ­¥éª¤ 3: æ¸…ç†æ— å…³æ ‡ç­¾")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	cleanedContent := removeTags(htmlContent, []string{"script", "style", "iframe", "noscript"})
	fmt.Printf("ç§»é™¤åå†…å®¹é•¿åº¦: %d å­—ç¬¦\n", len(cleanedContent))

	// æå–æœ‰æ•ˆæ–‡æœ¬
	fmt.Println("ğŸ” æ­¥éª¤ 4: æå–æœ‰æ•ˆæ–‡æœ¬å†…å®¹")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

	paragraphs := extractParagraphs(cleanedContent)
	validTexts := filterValidTexts(paragraphs)

	fmt.Printf("æ‰¾åˆ°æ–‡æœ¬å…ƒç´ æ€»æ•°: %d\n", len(paragraphs))
	fmt.Printf("âœ… æœ‰æ•ˆæ–‡æœ¬æ®µè½æ•°: %d\n", len(validTexts))
	fmt.Printf("âœ… æå–çš„å†…å®¹é•¿åº¦: %d å­—ç¬¦\n", len(strings.Join(validTexts, "\n\n")))

	// æ‰“å°é¢„è§ˆ
	if len(validTexts) > 0 {
		fmt.Println("ğŸ“‹ å‰3ä¸ªæœ‰æ•ˆæ®µè½é¢„è§ˆ:")
		for i, txt := range validTexts {
			if i >= 3 {
				break
			}
			fmt.Printf("   %d. %s%s\n", i+1, truncateString(txt, 80), cond(len(txt) > 80, "...", ""))
		}
	}

	// æ„å»ºæœ€ç»ˆå†…å®¹å¹¶ç”Ÿæˆæ€»ç»“
	contentText := strings.Join(validTexts, "\n\n")
	if contentText == "" {
		contentText = extractPlainText(htmlContent)
	}

	// ç”Ÿæˆå†…å®¹æ€»ç»“
	fmt.Println("ğŸ“ æ­¥éª¤ 5: ç”Ÿæˆå†…å®¹æ€»ç»“")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	summary := summarizeContent(title, metaDesc, contentText)
	fmt.Printf("âœ… æ€»ç»“ç”Ÿæˆå®Œæˆ, é•¿åº¦: %d å­—ç¬¦\n", len(summary))

	finalContent := fmt.Sprintf("æ ‡é¢˜ï¼š%s\n\næè¿°ï¼š%s\n\næ¥æºé“¾æ¥ï¼š%s\n\nå†…å®¹æ€»ç»“ï¼š\n%s",
		title,
		cond(metaDesc != "", metaDesc, "æ— æè¿°"),
		targetURL,
		summary)

	totalTime := time.Since(startTime)
	fmt.Println("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Println("âœ… URL è§£æå®Œæˆ")
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Printf("â±ï¸  æ€»è€—æ—¶: %dms\n", totalTime.Milliseconds())
	fmt.Printf("ğŸ“Š æå–ç»Ÿè®¡:\n")
	fmt.Printf("   - æ ‡é¢˜: %s...\n", truncateString(title, 50))
	fmt.Printf("   - æè¿°: %s...\n", truncateString(metaDesc, 50))
	fmt.Printf("   - å†…å®¹: %s... (å…± %d å­—ç¬¦)\n", truncateString(contentText, 50), len(contentText))
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

	return &ExtractedContent{
		Title:     title,
		URL:       targetURL,
		Content:   finalContent,
		Timestamp: time.Now().Format("2006-01-02 15:04:05"),
	}, nil
}

// è¾…åŠ©å‡½æ•°

func extractTitle(html string) string {
	// æå– <title> æ ‡ç­¾å†…å®¹
	// æ”¯æŒ <title> å’Œ <title anyattr="value"> æ ¼å¼
	lowerHtml := strings.ToLower(html)

	// æŸ¥æ‰¾ <title å¼€å§‹ä½ç½®
	start := strings.Index(lowerHtml, "<title")
	if start == -1 {
		return "æ— æ ‡é¢˜"
	}

	// æŸ¥æ‰¾ > çš„ä½ç½®ï¼ˆæ ‡ç­¾ç»“æŸï¼‰
	tagEnd := strings.Index(html[start:], ">")
	if tagEnd == -1 {
		return "æ— æ ‡é¢˜"
	}
	start += tagEnd + 1

	// æŸ¥æ‰¾ </title> çš„ä½ç½®
	end := strings.Index(lowerHtml[start:], "</title>")
	if end == -1 {
		return "æ— æ ‡é¢˜"
	}

	title := html[start : start+end]
	// ç§»é™¤æ¢è¡Œå’Œå¤šä½™ç©ºæ ¼
	title = strings.ReplaceAll(title, "\n", " ")
	title = strings.ReplaceAll(title, "\r", "")
	title = strings.ReplaceAll(title, "\t", " ")
	title = strings.TrimSpace(title)

	// å¦‚æœæ ‡é¢˜ä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œå°è¯•ä» meta og:title è·å–
	if len(title) == 0 || len(title) < 2 {
		ogTitle := extractMetaProperty(html, "og:title")
		if ogTitle != "" {
			return ogTitle
		}
	}

	return title
}

func extractMetaDescription(html string) string {
	// æå– meta description

	if idx := strings.Index(strings.ToLower(html), "name=\"description\""); idx != -1 {
		start := strings.Index(html[idx:], "content=\"")
		if start != -1 {
			start += idx + 9
			end := strings.Index(html[start:], "\"")
			if end != -1 {
				return html[start : start+end]
			}
		}
	}

	if idx := strings.Index(strings.ToLower(html), "name='description'"); idx != -1 {
		start := strings.Index(html[idx:], "content='")
		if start != -1 {
			start += idx + 9
			end := strings.Index(html[start:], "'")
			if end != -1 {
				return html[start : start+end]
			}
		}
	}

	return ""
}

func extractMetaProperty(html string, property string) string {
	// æå– meta propertyï¼Œå¦‚ og:title
	searchStr := fmt.Sprintf(`property="%s"`, property)
	idx := strings.Index(html, searchStr)
	if idx == -1 {
		searchStr = fmt.Sprintf(`property='%s'`, property)
		idx = strings.Index(html, searchStr)
	}
	if idx == -1 {
		return ""
	}

	contentStart := strings.Index(html[idx:], "content=\"")
	if contentStart == -1 {
		contentStart = strings.Index(html[idx:], "content='")
	}
	if contentStart == -1 {
		return ""
	}
	contentStart += idx + 9

	end := strings.Index(html[contentStart:], `"`)
	if end == -1 {
		return ""
	}

	return strings.TrimSpace(html[contentStart : contentStart+end])
}

func removeTags(html string, tagsToRemove []string) string {
	content := html
	for _, tag := range tagsToRemove {
		// æ­£ç¡®ç§»é™¤æ•´ä¸ªæ ‡ç­¾ï¼ˆåŒ…æ‹¬å†…å®¹ï¼‰
		lowerContent := strings.ToLower(content)
		maxIterations := 10000 // é˜²æ­¢æ­»å¾ªç¯
		iteration := 0
		for {
			iteration++
			if iteration > maxIterations {
				fmt.Printf("âš ï¸  è­¦å‘Š: ç§»é™¤æ ‡ç­¾ <%s> è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¯èƒ½å­˜åœ¨ HTML ç»“æ„é—®é¢˜\n", tag)
				break
			}
			
			startTag := "<" + tag
			endTag := "</" + tag + ">"

			startIdx := strings.Index(lowerContent, startTag)
			if startIdx == -1 {
				break
			}

			// æŸ¥æ‰¾ç»“æŸæ ‡ç­¾çš„ä½ç½®
			endIdx := strings.Index(lowerContent[startIdx:], endTag)
			if endIdx == -1 {
				// æ²¡æœ‰æ‰¾åˆ°ç»“æŸæ ‡ç­¾ï¼Œåªç§»é™¤å¼€å§‹æ ‡ç­¾
				tagEnd := strings.Index(content[startIdx:], ">")
				if tagEnd == -1 {
					break
				}
				content = content[:startIdx] + content[startIdx+tagEnd+1:]
				lowerContent = strings.ToLower(content)
				continue
			}

			// ç§»é™¤ä»å¼€å§‹æ ‡ç­¾åˆ°ç»“æŸæ ‡ç­¾ä¹‹é—´çš„æ‰€æœ‰å†…å®¹
			content = content[:startIdx] + content[startIdx+endIdx+len(endTag):]
			lowerContent = strings.ToLower(content)
		}
	}
	return content
}

func extractParagraphs(html string) []string {
	var paragraphs []string

	// æå– <p> æ ‡ç­¾å†…å®¹
	content := strings.ToLower(html)
	idx := 0

	for {
		start := strings.Index(content[idx:], "<p")
		if start == -1 {
			break
		}
		start += idx

		// æ‰¾åˆ° > çš„ä½ç½®
		endTag := strings.Index(content[start:], ">")
		if endTag == -1 {
			break
		}
		start += endTag + 1

		// æ‰¾åˆ° </p> çš„ä½ç½®
		end := strings.Index(content[start:], "</p>")
		if end == -1 {
			break
		}

		text := html[start : start+end]
		paragraphs = append(paragraphs, strings.TrimSpace(text))

		idx = start + end + 4
	}

	// å¦‚æœæ²¡æœ‰ p æ ‡ç­¾ï¼Œå°è¯•å…¶ä»–æ ‡ç­¾
	if len(paragraphs) == 0 {
		// æå– h1-h6, li
		for _, tag := range []string{"h1", "h2", "h3", "h4", "h5", "h6", "li"} {
			tagCount := strings.Count(strings.ToLower(html), "<"+tag)
			for i := 0; i < tagCount; i++ {
				tempContent := html
				for j := 0; j <= i; j++ {
					start := strings.Index(strings.ToLower(tempContent), "<"+tag)
					if start == -1 {
						break
					}
					endTag := strings.Index(tempContent[start:], ">")
					if endTag == -1 {
						break
					}
					start += endTag + 1

					end := strings.Index(tempContent[start:], "</"+tag+">")
					if end == -1 {
						break
					}

					text := tempContent[start : start+end]
					paragraphs = append(paragraphs, strings.TrimSpace(text))

					tempContent = tempContent[start+end+len(tag)+3:]
				}
			}
		}
	}

	return paragraphs
}

func filterValidTexts(texts []string) []string {
	var valid []string
	for _, text := range texts {
		// ç§»é™¤ HTML æ ‡ç­¾ï¼ˆç®€å•å®ç°ï¼‰
		text = removeHTMLTags(text)
		text = strings.TrimSpace(text)
		if len(text) > 10 { // è‡³å°‘10ä¸ªå­—ç¬¦
			valid = append(valid, text)
		}
	}
	return valid
}

// removeHTMLTags ç§»é™¤æ–‡æœ¬ä¸­çš„ HTML æ ‡ç­¾
func removeHTMLTags(text string) string {
	// ç§»é™¤ <a href="...">text</a> è¿™æ ·çš„æ ‡ç­¾
	for {
		start := strings.Index(text, "<")
		if start == -1 {
			break
		}
		end := strings.Index(text[start:], ">")
		if end == -1 {
			break
		}
		text = text[:start] + text[start+end+1:]
	}

	// æ¸…ç†å¤šä½™çš„ç©ºæ ¼
	text = strings.ReplaceAll(text, "  ", " ")
	for strings.Contains(text, "  ") {
		text = strings.ReplaceAll(text, "  ", " ")
	}

	return strings.TrimSpace(text)
}

func extractPlainText(html string) string {
	// ç®€å•çš„æ–‡æœ¬æå–
	content := html
	// ç§»é™¤æ‰€æœ‰ HTML æ ‡ç­¾
	for {
		start := strings.Index(content, "<")
		if start == -1 {
			break
		}
		end := strings.Index(content, ">")
		if end == -1 {
			break
		}
		content = content[:start] + content[end+1:]
	}

	// æ¸…ç†ç©ºç™½
	lines := strings.Split(content, "\n")
	var cleanLines []string
	for _, line := range lines {
		line = strings.TrimSpace(line)
		if strings.Count(line, "") > 10 {
			cleanLines = append(cleanLines, line)
		}
	}

	return strings.Join(cleanLines, "\n\n")
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

func truncateString(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	return s[:maxLen]
}

func cond(condition bool, trueVal, falseVal string) string {
	if condition {
		return trueVal
	}
	return falseVal
}

// summarizeContent ç”Ÿæˆå†…å®¹æ€»ç»“
func summarizeContent(title, metaDesc, content string) string {
	var summaryParts []string

	// æ€»æ˜¯åŒ…å«æ ‡é¢˜
	titleLine := fmt.Sprintf("ã€%sã€‘", title)
	summaryParts = append(summaryParts, titleLine)

	// å¦‚æœæœ‰æè¿°ï¼Œä¼˜å…ˆä½¿ç”¨æè¿°
	if metaDesc != "" {
		summaryParts = append(summaryParts, metaDesc)
	}

	// æå–å…³é”®æ®µè½
	lines := strings.Split(content, "\n")
	var keyParagraphs []string

	// æŸ¥æ‰¾åŒ…å«é‡è¦å…³é”®è¯çš„æ®µè½
	keywords := []string{"é‡è¦", "å…³é”®", "æ³¨æ„", "æ€»ç»“", "ç»“è®º", "å› æ­¤", "æ‰€ä»¥", "é¦–å…ˆ", "å…¶æ¬¡", "æœ€å"}

	for _, line := range lines {
		line = strings.TrimSpace(line)
		if len(line) < 10 {
			continue
		}

		// æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯
		containsKeyword := false
		lineLower := strings.ToLower(line)
		for _, keyword := range keywords {
			if strings.Contains(lineLower, strings.ToLower(keyword)) {
				containsKeyword = true
				break
			}
		}

		// é™åˆ¶æ€»ç»“é•¿åº¦
		if containsKeyword || len(keyParagraphs) < 3 {
			keyParagraphs = append(keyParagraphs, line)
			if len(keyParagraphs) >= 5 {
				break
			}
		}
	}

	// æ·»åŠ å…³é”®æ®µè½
	if len(keyParagraphs) > 0 {
		summaryParts = append(summaryParts, "\nã€å…³é”®è¦ç‚¹ã€‘")
		for i, para := range keyParagraphs {
			if i >= 3 {
				break
			}
			summaryParts = append(summaryParts, fmt.Sprintf("â€¢ %s", truncateString(para, 150)))
		}
	}

	// æ·»åŠ åŸæ–‡é“¾æ¥æç¤º
	summaryParts = append(summaryParts, "\nï¼ˆæ­¤å†…å®¹ä¸ºè‡ªåŠ¨ç”Ÿæˆçš„æ€»ç»“ï¼Œè¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹åŸæ–‡ï¼‰")

	return strings.Join(summaryParts, "\n")
}
